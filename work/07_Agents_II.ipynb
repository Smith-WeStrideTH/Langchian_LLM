{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1H62LJqni4p"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "from pprint import pprint\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQC0wQMvnjQJ",
        "outputId": "f7337a2b-c726-4468-e531-f7bbc68b38ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API Key loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv('./credential/cred.env')\n",
        "\n",
        "# Get the API key from the environment variables\n",
        "api_key = os.environ.get(\"API_KEY\")\n",
        "\n",
        "# Check if the API key was found\n",
        "if api_key:\n",
        "  print(\"API Key loaded successfully.\")\n",
        "else:\n",
        "  print(\"API Key not found in the environment variables.\")\n",
        "os.environ[\"OPENAI_API_KEY\"] = api_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMNPRphfmOIO"
      },
      "source": [
        "# Chapter 7. Agents II\n",
        "\n",
        "บทที่ 6 ได้แนะนำสถาปัตยกรรมตัวแทน ซึ่งเป็นสถาปัตยกรรม LLM ที่ทรงพลังที่สุดที่เราได้เห็นจนถึงขณะนี้ เป็นการยากที่จะพูดเกินจริงถึงศักยภาพของการผสมผสานนี้ของการเขียนพรอมต์แบบ chain-of-thought การใช้เครื่องมือ และการวนซ้ำ\n",
        "\n",
        "**บทนี้กล่าวถึงส่วนขยายสองส่วนของสถาปัตยกรรมตัวแทนที่ปรับปรุงประสิทธิภาพสำหรับกรณีการใช้งานบางอย่าง:**\n",
        "\n",
        "- **Reflection (การสะท้อนกลับ)**\n",
        "การนำอีกหน้าหนึ่งจากคลังเก็บรูปแบบการคิดของมนุษย์ สิ่งนี้เกี่ยวกับการให้โอกาสแอปพลิเคชัน LLM ของคุณในการวิเคราะห์ผลลัพธ์และตัวเลือกในอดีต พร้อมกับความสามารถในการจดจำการสะท้อนกลับจากการวนซ้ำในอดีต\n",
        "\n",
        "- **Multi-agent (หลายตัวแทน)**\n",
        "เช่นเดียวกับที่ทีมสามารถบรรลุเป้าหมายได้มากกว่าบุคคลคนเดียว มีปัญหาบางอย่างที่สามารถแก้ไขได้ดีที่สุดโดยทีมของตัวแทน LLM\n",
        "\n",
        "มาเริ่มต้นด้วยการสะท้อนกลับกัน"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBcObMl5mmXe"
      },
      "source": [
        "# Reflection\n",
        "**การสะท้อนกลับ**\n",
        "\n",
        "เทคนิคการเขียนพรอมต์อย่างหนึ่งที่เรายังไม่ได้กล่าวถึงคือ การสะท้อนกลับ (หรือที่เรียกว่าการวิจารณ์ตนเอง) การสะท้อนกลับคือการสร้างลูประหว่างพรอมต์ผู้สร้างและพรอมต์ผู้แก้ไข สิ่งนี้สะท้อนกระบวนการสร้างสรรค์สำหรับสิ่งประดิษฐ์ที่สร้างโดยมนุษย์หลายอย่าง เช่น บทนี้ที่คุณกำลังอ่านอยู่ ซึ่งเป็นผลมาจากการโต้ตอบระหว่างผู้เขียน ผู้ตรวจทาน และบรรณาธิการจนกว่าทุกคนจะพอใจกับผลิตภัณฑ์ขั้นสุดท้าย\n",
        "\n",
        "เช่นเดียวกับเทคนิคการเขียนพรอมต์หลายอย่างที่เราได้เห็นมาจนถึงตอนนี้ การสะท้อนกลับสามารถรวมกับเทคนิคอื่นๆ เช่น chain-of-thought และการเรียกใช้งานเครื่องมือได้ ในส่วนนี้ เราจะดูการสะท้อนกลับแบบแยกส่วน เพื่อความชัดเจน\n",
        "\n",
        "สามารถเปรียบเทียบได้กับโหมดการคิดของมนุษย์ที่เรียกว่า ระบบ 1 (ตอบสนองหรือสัญชาตญาณ) และระบบ 2 (มีระเบียบวิธีและมีการสะท้อนกลับ) ซึ่ง Daniel Kahneman ได้แนะนำครั้งแรกในหนังสือ Thinking, Fast and Slow (Farrar, Straus and Giroux, 2011) เมื่อนำไปใช้ถูกต้อง การวิจารณ์ตนเองสามารถช่วยให้แอปพลิเคชัน LLM เข้าใกล้สิ่งที่คล้ายคลึงกับพฤติกรรมของระบบ 2 ได้มากขึ้น ดังรูป\n",
        "\n",
        "---\n",
        "\n",
        "<img align=\"top\" src=\"./pics/Figure7-1.png\"     style=\" width:380px; padding: 10px; \" >\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4jlYb9znRtb"
      },
      "source": [
        "เราจะนำการสะท้อนกลับไปใช้เป็นกราฟที่มีสองโหนด: `generate` และ `reflect` กราฟนี้จะมีภารกิจในการเขียนเรียงความสามย่อหน้า โดยโหนด generate เขียนหรือแก้ไขร่างของเรียงความ และ `reflect` เขียนคำวิจารณ์เพื่อแจ้งการแก้ไขครั้งถัดไป เราจะเรียกใช้ลูปจำนวนครั้งคงที่ แต่รูปแบบที่แตกต่างกันของเทคนิคนี้คือการให้โหนด `reflect` ตัดสินใจว่าจะเสร็จสิ้นเมื่อใด\n",
        "\n",
        "มาดูกันว่ามันมีลักษณะอย่างไร:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLZxxTQXmMMy"
      },
      "outputs": [],
      "source": [
        "from typing import Annotated, TypedDict\n",
        "\n",
        "from langchain_core.messages import (\n",
        "    AIMessage,\n",
        "    BaseMessage,\n",
        "    HumanMessage,\n",
        "    SystemMessage,\n",
        ")\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "from langgraph.graph import END, START, StateGraph\n",
        "from langgraph.graph.message import add_messages\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "class State(TypedDict):\n",
        "    messages: Annotated[list[BaseMessage], add_messages]\n",
        "\n",
        "generate_prompt = SystemMessage(\n",
        "    \"You are an essay assistant tasked with writing excellent 3-paragraph essays.\"\n",
        "    \" Generate the best essay possible for the user's request.\"\n",
        "    \" If the user provides critique, respond with a revised version of your previous attempts.\"\n",
        ")\n",
        "\n",
        "def generate(state: State) -> State:\n",
        "    answer = model.invoke([generate_prompt] + state[\"messages\"])\n",
        "    return {\"messages\": [answer]}\n",
        "\n",
        "reflection_prompt = SystemMessage(\n",
        "    \"\"\"You are a teacher grading an essay submission. Generate critique and\n",
        "        recommendations for the user's submission.\"\"\"\n",
        "    \"\"\" Provide detailed recommendations, including requests for length, depth,\n",
        "        style, etc.\"\"\"\n",
        ")\n",
        "\n",
        "def reflect(state: State) -> State:\n",
        "    # Invert the messages to get the LLM to reflect on its own output\n",
        "    cls_map = {AIMessage: HumanMessage, HumanMessage: AIMessage}\n",
        "    # First message is the original user request. We hold it the same for all nodes\n",
        "    translated = [reflection_prompt, state[\"messages\"][0]] + [\n",
        "        cls_map[msg.__class__](content=msg.content) for msg in state[\"messages\"][1:]\n",
        "    ]\n",
        "    answer = model.invoke(translated)\n",
        "    # We treat the output of this as human feedback for the generator\n",
        "    return {\"messages\": [HumanMessage(content=answer.content)]}\n",
        "\n",
        "def should_continue(state: State):\n",
        "    if len(state[\"messages\"]) > 6:\n",
        "        # End after 3 iterations, each with 2 messages\n",
        "        return END\n",
        "    else:\n",
        "        return \"reflect\"\n",
        "\n",
        "builder = StateGraph(State)\n",
        "builder.add_node(\"generate\", generate)\n",
        "builder.add_node(\"reflect\", reflect)\n",
        "builder.add_edge(START, \"generate\")\n",
        "builder.add_conditional_edges(\"generate\", should_continue)\n",
        "builder.add_edge(\"reflect\", \"generate\")\n",
        "\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "DHytQeWZnldm",
        "outputId": "a7837ab9-eea6-4352-e55a-4a75380b507c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "image_bytes = graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\n",
        "\n",
        "display(Image(data=image_bytes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrGaUzXioAK9"
      },
      "source": [
        "สังเกตว่าโหนด `reflect` หลอกให้ LLM คิดว่ากำลังวิจารณ์เรียงความที่เขียนโดยผู้ใช้ และในเวลาเดียวกัน โหนด `generate` ถูกทำให้คิดว่าคำวิจารณ์มาจากผู้ใช้\n",
        "- การลวงนี้จำเป็นเนื่องจาก LLM ที่ได้รับการปรับแต่งด้วยการสนทนาได้รับการฝึกอบรมบนคู่ของข้อความระหว่างมนุษย์กับ AI ดังนั้น ลำดับของข้อความจำนวนมากจากผู้เข้าร่วมรายเดียวกันจะส่งผลให้ประสิทธิภาพการทำงานต่ำ\n",
        "\n",
        "**อีกสิ่งหนึ่งที่ควรทราบ:**คุณอาจคาดหวังว่าจุดสิ้นสุดจะเกิดขึ้นหลังจากขั้นตอนการแก้ไข แต่ในสถาปัตยกรรมนี้เรามี**จำนวน**การวนซ้ำของลูป `generate-reflect` ที่กำหนดไว้ ดังนั้นเราจึงสิ้นสุดหลังจาก generate (เพื่อให้ชุดการแก้ไขล่าสุดที่ร้องขอได้รับการจัดการ) รูปแบบหนึ่งของสถาปัตยกรรมนี้จะแทนที่ให้ขั้นตอนการสะท้อนกลับตัดสินใจสิ้นสุดกระบวนการ (เมื่อไม่มีความคิดเห็นเพิ่มเติม)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSeX-RDlo7uj"
      },
      "source": [
        "มาดูกันว่าหนึ่งในคำวิจารณ์มีลักษณะอย่างไร:\n",
        "\n",
        "```\n",
        "{\n",
        "    'messages': [\n",
        "        HumanMessage(content='Your essay on the topicality of \"The Little Prince\"\n",
        "            and its message in modern life is well-written and insightful. You\n",
        "            have effectively highlighted the enduring relevance of the book\\'s\n",
        "            themes and its importance in today\\'s society. However, there are a\n",
        "            few areas where you could enhance your essay:\\n\\n1. **Depth**:\n",
        "            While you touch upon the themes of cherishing simple joys,\n",
        "            nurturing connections, and understanding human relationships,\n",
        "            consider delving deeper into each of these themes. Provide specific\n",
        "            examples from the book to support your points and explore how these\n",
        "            themes manifest in contemporary life.\\n\\n2. **Analysis**: Consider\n",
        "            analyzing how the book\\'s messages can be applied to current\n",
        "            societal issues or personal experiences. For instance, you could\n",
        "            discuss how the Little Prince\\'s perspective on materialism relates\n",
        "            to consumer culture or explore how his approach to relationships\n",
        "            can inform interpersonal dynamics in the digital age.\\n\\n3.\n",
        "            **Length**: Expand on your ideas by adding more examples,\n",
        "            discussing counterarguments, or exploring the cultural impact of\n",
        "            \"The Little Prince\" in different parts of the world. This will\n",
        "            enrich the depth of your analysis and provide a more comprehensive\n",
        "            understanding of the book\\'s relevance.\\n\\n4. **Style**: Your essay\n",
        "            is clear and well-structured. To enhance the engagement of your\n",
        "            readers, consider incorporating quotes from the book to illustrate\n",
        "            key points or including anecdotes to personalize your analysis.\n",
        "            \\n\\n5. **Conclusion**: Conclude your essay by summarizing the\n",
        "            enduring significance of \"The Little Prince\" and how its messages\n",
        "            can inspire positive change in modern society. Reflect on the\n",
        "            broader implications of the book\\'s themes and leave the reader\n",
        "            with a lasting impression.\\n\\nBy expanding on your analysis,\n",
        "            incorporating more examples, and deepening your exploration of the\n",
        "            book\\'s messages, you can create a more comprehensive and\n",
        "            compelling essay on the topicality of \"The Little Prince\" in modern\n",
        "            life. Well done on your thoughtful analysis, and keep up the good\n",
        "            work!', id='70c22b1d-ec96-4dc3-9fd0-d2c6463f9e2c'),\n",
        "    ],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Irg0pk5pKbX"
      },
      "source": [
        "และผลลัพธ์สุดท้าย:\n",
        "```\n",
        "{\n",
        "    'messages': [\n",
        "        AIMessage(content='\"The Little Prince\" by Antoine de Saint-Exupéry stands\n",
        "            as a timeless masterpiece that continues to offer profound insights\n",
        "            into human relationships and values, resonating with readers across\n",
        "            generations. The narrative of the Little Prince\\'s travels and\n",
        "            encounters with a myriad of characters serves as a rich tapestry of\n",
        "            allegorical representations, inviting readers to delve deeper into\n",
        "            the complexities of interpersonal connections and the essence of\n",
        "            existence. Through critical analysis of the Prince\\'s interactions\n",
        "            with characters like the Fox and the Rose, readers can glean\n",
        "            valuable lessons on empathy, understanding, and the significance of\n",
        "            genuine human connections. By examining these encounters through a\n",
        "            critical lens and drawing parallels to real-life scenarios, the\n",
        "            book\\'s messages come to life with renewed relevance and depth.\n",
        "            \\n\\nIn today\\'s fast-paced and interconnected world, the themes\n",
        "            explored in \"The Little Prince\" offer poignant reflections on the\n",
        "            challenges and opportunities of modern society. By integrating\n",
        "            contemporary examples and case studies that illustrate how the\n",
        "            book\\'s principles manifest in current societal trends and\n",
        "            interpersonal dynamics, readers can better appreciate the enduring\n",
        "            relevance of the Prince\\'s timeless wisdom. Through a comparative\n",
        "            analysis that juxtaposes the struggles faced by the characters in\n",
        "            the book with the complexities of today\\'s world, readers can gain\n",
        "            a deeper understanding of how the book\\'s messages transcend time\n",
        "            and offer universal truths that guide individuals in navigating the\n",
        "            intricacies of human relationships and societal dynamics.\n",
        "            \\n\\nMoreover, the global impact of \"The Little Prince\" underscores\n",
        "            its universal resonance and cultural significance. By exploring how\n",
        "            the book\\'s themes have resonated with audiences worldwide and how\n",
        "            cultural interpretations shape the understanding of its messages,\n",
        "            readers can appreciate the depth and breadth of Saint-Exupéry\\'s\n",
        "            work. As readers reflect on the book\\'s enduring relevance and the\n",
        "            lessons it imparts, they are encouraged to actively apply these\n",
        "            insights in their daily lives, fostering a more empathetic and\n",
        "            compassionate society. By offering a call to action that prompts\n",
        "            readers to embrace the book\\'s teachings and integrate them into\n",
        "            their interactions and relationships, the essay aims to inspire\n",
        "            individuals to embody the spirit of the Little Prince and cultivate\n",
        "            meaningful connections that transcend boundaries and enrich lives\n",
        "            in a rapidly changing world.', response_metadata={'token_usage':\n",
        "            {'completion_tokens': 420, 'prompt_tokens': 2501, 'total_tokens':\n",
        "            2921}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': None,\n",
        "            'finish_reason': 'stop', 'logprobs': None},\n",
        "            id='run-2e8f9f13-f625-4820-9c8b-b64e1c23daa2-0', usage_metadata=\n",
        "            {'input_tokens': 2501, 'output_tokens': 420, 'total_tokens': 2921}),\n",
        "    ],\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_prompt = HumanMessage(content=\"Write a 3-paragraph essay about the importance of kindness. (make sure your output is thai language)\")\n",
        "result = graph.invoke({\"messages\": [user_prompt]})\n",
        "result\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvUpUfPBpZPa"
      },
      "source": [
        "การสะท้อนกลับประเภทง่ายๆ นี้อาจช่วยปรับปรุงประสิทธิภาพได้บางครั้ง โดยการให้ LLM มีโอกาสปรับปรุงผลลัพธ์หลายครั้ง และโดยการให้โหนด `reflect` รับบทบาทที่แตกต่างออกไปขณะวิจารณ์ผลลัพธ์\n",
        "\n",
        "มีรูปแบบที่เป็นไปได้หลายอย่างของสถาปัตยกรรมนี้ สำหรับหนึ่งในนั้น เราสามารถรวมขั้นตอนการสะท้อนกลับเข้ากับสถาปัตยกรรมตัวแทนของ บทที่ 6\n",
        "- โดยเพิ่มเป็นโหนดสุดท้ายก่อนส่งเอาต์พุตไปยังผู้ใช้ สิ่งนี้จะทำให้คำวิจารณ์ปรากฏว่ามาจากผู้ใช้ (ดังที่กล่าวไว้ข้างต้น)\n",
        "- และให้โอกาสแอปพลิเคชันในการปรับปรุงผลลัพธ์ขั้นสุดท้ายโดยไม่ต้องมีการแทรกแซงโดยตรงจากผู้ใช้ เห็นได้ชัดว่าวิธีนี้อาจส่งผลให้เกิดเวลาแฝงที่สูงขึ้น\n",
        "\n",
        "ในบางกรณีการใช้งาน อาจเป็นประโยชน์ในการอ้างอิงคำวิจารณ์ด้วยข้อมูลภายนอก ตัวอย่างเช่น หากคุณกำลังเขียนตัวแทนการสร้างโค้ด คุณอาจมีขั้นตอนก่อน `reflect` ที่จะเรียกใช้โค้ดผ่าน `linter` หรือคอมไพล์เลอร์ และรายงานข้อผิดพลาดใดๆ เป็นอินพุตไปยัง `reflect`\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guTlT58dp0vM"
      },
      "source": [
        "**เคล็ดลับ** : เมื่อใดก็ตามที่วิธีนี้เป็นไปได้ เราขอแนะนำให้ลองใช้ เนื่องจากมีแนวโน้มที่จะเพิ่มคุณภาพของผลลัพธ์ขั้นสุดท้าย"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kJHtnXlOqC-L"
      },
      "source": [
        "# Subgraphs in LangGraph\n",
        "\n",
        "\n",
        "ก่อนที่เราจะเจาะลึกรายละเอียดสถาปัตยกรรมหลายตัวแทน มาดูแนวคิดทางเทคนิคที่สำคัญใน LangGraph ที่ช่วยให้สามารถทำได้ Subgraphs คือ**กราฟที่ใช้เป็นส่วนหนึ่งของกราฟอื่นๆ** ต่อไปนี้คือกรณีการใช้งานบางอย่างสำหรับ subgraphs:\n",
        "\n",
        "- การสร้างระบบหลายตัวแทน (กล่าวถึงในหัวข้อถัดไป)\n",
        "\n",
        "- เมื่อคุณต้องการนำชุดโหนดกลับมาใช้ใหม่ในหลายกราฟ คุณสามารถกำหนดโหนดเหล่านั้นเพียงครั้งเดียวใน subgraph จากนั้นจึงใช้ในกราฟหลักหลายตัว\n",
        "\n",
        "- เมื่อคุณต้องการให้ทีมต่างๆ ทำงานในส่วนต่างๆ ของกราฟอย่างอิสระ คุณสามารถกำหนดแต่ละส่วนเป็น subgraph และตราบใดที่อินเทอร์เฟซ subgraph (รูปแบบอินพุตและเอาต์พุต) เป็นไปตามที่กำหนด กราฟหลักสามารถสร้างได้โดยไม่ทราบรายละเอียดใดๆ ของ subgraph\n",
        "\n",
        "**มีสองวิธีในการเพิ่มโหนด subgraph ลงในกราฟหลัก:**\n",
        "\n",
        "- **เพิ่มโหนดที่เรียกใช้งาน subgraph โดยตรง**\n",
        "วิธีนี้มีประโยชน์เมื่อกราฟหลักและ subgraph ใช้คีย์สถานะร่วมกัน และคุณไม่จำเป็นต้องแปลงสถานะในระหว่างทางเข้าหรือออก\n",
        "\n",
        "- **เพิ่มโหนดที่มีฟังก์ชันที่เรียกใช้งาน subgraph**\n",
        "วิธีนี้มีประโยชน์เมื่อกราฟหลักและ subgraph มีรูปแบบสถานะที่แตกต่างกัน และคุณจำเป็นต้องแปลงสถานะก่อนหรือหลังการเรียกใช้งาน subgraph\n",
        "\n",
        "มาดูกันทีละวิธี"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOeqPw8nqg54"
      },
      "source": [
        "## Calling a Subgraph Directly\n",
        "\n",
        "\n",
        "**วิธีที่ง่ายที่สุดในการสร้างโหนด subgraph คือการแนบ subgraph โดยตรงเป็นโหนด**\n",
        "- เมื่อทำเช่นนั้น สิ่งสำคัญคือกราฟหลักและ subgraph ต้องใช้คีย์สถานะร่วมกัน เนื่องจากคีย์ที่ใช้ร่วมกันเหล่านั้นคือสิ่งที่พวกเขาสามารถใช้เพื่อสื่อสาร (หากกราฟและ subgraph ของคุณไม่มีคีย์ใดๆ ที่ใช้ร่วมกัน ให้ดูส่วนถัดไป)\n",
        "\n",
        "**หมายเหตุ:**\n",
        "- หากคุณส่งผ่านคีย์พิเศษไปยังโหนด subgraph (นั่นคือ นอกเหนือจากคีย์ที่ใช้ร่วมกัน) คีย์พิเศษเหล่านั้นจะถูกโหนด subgraph ละเว้น\n",
        "- ในทำนองเดียวกัน หากคุณส่งคืนคีย์พิเศษจาก subgraph คีย์พิเศษเหล่านั้นจะถูกกราฟหลักละเว้น\n",
        "\n",
        "มาดูกันว่ามันทำงานอย่างไรในทางปฏิบัติ:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PL51PcqFnyEG"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph, END\n",
        "from typing import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    foo: str # this key is shared with the subgraph\n",
        "\n",
        "class SubgraphState(TypedDict):\n",
        "    foo: str # this key is shared with the parent graph\n",
        "    bar: str\n",
        "\n",
        "# Define subgraph\n",
        "def subgraph_node(state: SubgraphState):\n",
        "    # note that this subgraph node can communicate with the parent graph via the shared \"foo\" key\n",
        "    return {\"foo\": state[\"foo\"] + \"bar\"}\n",
        "\n",
        "subgraph_builder = StateGraph(SubgraphState)\n",
        "subgraph_builder.add_node(subgraph_node)\n",
        "# Add an edge to connect START to subgraph_node to initiate the workflow\n",
        "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
        "subgraph = subgraph_builder.compile()\n",
        "\n",
        "# Define parent graph\n",
        "builder = StateGraph(State)\n",
        "# Instead of adding the subgraph directly, add a node that calls the subgraph's invoke method\n",
        "builder.add_node(\"subgraph_caller\", lambda state: subgraph.invoke(state)) \n",
        "builder.add_edge(START, \"subgraph_caller\")\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxgzdXf_w2pu"
      },
      "outputs": [],
      "source": [
        "# prompt: display graph\n",
        "\n",
        "image_bytes = graph.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\n",
        "\n",
        "display(Image(data=image_bytes))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TzBQihqyyUio"
      },
      "source": [
        "## Calling a Subgraph with a Function\n",
        "\n",
        "\n",
        "คุณอาจต้องการกำหนด subgraph ที่มีรูปแบบแผนผังที่แตกต่างออกไปอย่างสิ้นเชิง\n",
        "\n",
        "1.ในกรณีนั้น คุณสามารถสร้างโหนดที่มีฟังก์ชันที่เรียกใช้งาน `subgraph` ฟังก์ชันนี้จะต้องแปลงอินพุต (สถานะหลัก) เป็นสถานะ `subgraph` ก่อนเรียกใช้งาน `subgraph` และแปลงผลลัพธ์กลับเป็นสถานะหลักก่อนส่งคืนการอัปเดตสถานะจากโหนด\n",
        "\n",
        "มาดูกันว่ามันทำงานอย่างไร:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ZPlYGPVx3vH"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import START, StateGraph, END\n",
        "from typing import TypedDict\n",
        "\n",
        "class State(TypedDict):\n",
        "    foo: str\n",
        "\n",
        "class SubgraphState(TypedDict):\n",
        "    # none of these keys are shared with the parent graph state\n",
        "    bar: str\n",
        "    baz: str\n",
        "\n",
        "# Define subgraph\n",
        "def subgraph_node(state: SubgraphState):\n",
        "    return {\"bar\": state[\"bar\"] + \"baz\"}\n",
        "\n",
        "subgraph_builder = StateGraph(SubgraphState)\n",
        "subgraph_builder.add_node(subgraph_node)\n",
        "subgraph_builder.add_edge(START, \"subgraph_node\")\n",
        "subgraph = subgraph_builder.compile()\n",
        "\n",
        "# Define parent graph\n",
        "def node(state: State):\n",
        "    # transform the state to the subgraph state\n",
        "    response = subgraph.invoke({\"bar\": state[\"foo\"]})\n",
        "    # transform response back to the parent state\n",
        "    return {\"foo\": response[\"bar\"]}\n",
        "\n",
        "builder = StateGraph(State)\n",
        "# note that we are using `node` function instead of a compiled subgraph\n",
        "builder.add_node(node)\n",
        "builder.add_edge(START, \"node\")\n",
        "graph = builder.compile()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NpEiZ1j-lC0"
      },
      "source": [
        "ตอนนี้ที่เรารู้วิธีการใช้ subgraphs แล้ว มาดูหนึ่งในกรณีการใช้งานที่สำคัญสำหรับ subgraphs: สถาปัตยกรรมหลายตัวแทน\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ib-W-aRi_QIa"
      },
      "source": [
        "# Multi-Agent Architectures\n",
        "\n",
        "**สถาปัตยกรรมหลายตัวแทน**\n",
        "\n",
        "เมื่อตัวแทน LLM เติบโตขึ้นในขนาด ขอบเขต หรือความซับซ้อน ปัญหาหลายอย่างอาจปรากฏขึ้นและส่งผลกระทบต่อประสิทธิภาพ เช่นต่อไปนี้:\n",
        "\n",
        "- ตัวแทนได้รับเครื่องมือมากเกินไปในการเลือก และตัดสินใจไม่ดีว่าจะเรียกใช้เครื่องมือใดต่อไป (บทที่ 6 กล่าวถึงแนวทางในการแก้ปัญหานี้บางประการ)\n",
        "- บริบทซับซ้อนเกินไปสำหรับตัวแทนตัวเดียวที่จะติดตาม กล่าวคือ ขนาดของพรอมต์และจำนวนสิ่งที่กล่าวถึงเกินขีดความสามารถของโมเดลที่คุณใช้อยู่\n",
        "- คุณต้องการใช้ระบบย่อยเฉพาะสำหรับพื้นที่เฉพาะ เช่น การวางแผน การวิจัย การแก้ปัญหาทางคณิตศาสตร์ เป็นต้น\n",
        "ในการแก้ไขปัญหาดังกล่าว\n",
        "\n",
        "คุณอาจพิจารณาแบ่งแอปพลิเคชันของคุณออกเป็นตัวแทนขนาดเล็กหลายตัวที่เป็นอิสระ และประกอบเข้าด้วยกันเป็นระบบหลายตัวแทน ตัวแทนอิสระเหล่านี้สามารถง่ายได้เช่น พรอมต์และการเรียกใช้งาน LLM หรือซับซ้อนเช่น ตัวแทน ReAct (แนะนำใน บทที่ 6)\n",
        "\n",
        "ดังรูปนี้ แสดงวิธีต่างๆ ในการเชื่อมต่อตัวแทนในระบบหลายตัวแทน\n",
        "\n",
        "---\n",
        "\n",
        "<img align=\"top\" src=\"./pics/Figure7-3.png\"     style=\" width:380px; padding: 10px; \" >\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3xKCc4IhA8eV"
      },
      "source": [
        "มาดูรูป ละเอียดยิ่งขึ้น:\n",
        "\n",
        "- **เครือข่าย (Network):**\n",
        "\n",
        "ตัวแทนแต่ละตัวสามารถสื่อสารกับตัวแทนอื่นๆ ได้ทุกตัว\n",
        "ตัวแทนใดๆ ก็ตามสามารถตัดสินใจได้ว่าควรเรียกใช้ตัวแทนอื่นใดต่อไป\n",
        "- **ผู้ควบคุม (Supervisor):**\n",
        "\n",
        "ตัวแทนแต่ละตัวสื่อสารกับตัวแทนตัวเดียวที่เรียกว่า ผู้ควบคุม\n",
        "ตัวแทนผู้ควบคุมตัดสินใจว่าควรเรียกใช้ตัวแทนใด (หรือตัวแทนใดบ้าง) ต่อไป\n",
        "กรณีพิเศษของสถาปัตยกรรมนี้ใช้การเรียกใช้งาน LLM พร้อมกับเครื่องมือเป็นตัวแทนผู้ควบคุม ตามที่กล่าวถึงใน บทที่ 6\n",
        "- **ลำดับชั้น (Hierarchical):**\n",
        "\n",
        "คุณสามารถกำหนดระบบหลายตัวแทนที่มีผู้ควบคุมระดับสูง\n",
        "นี่คือลักษณะทั่วไปของสถาปัตยกรรมผู้ควบคุมและช่วยให้สามารถควบคุมโฟลว์ที่ซับซ้อนยิ่งขึ้น\n",
        "- **เวิร์กโฟลว์หลายตัวแทนแบบกำหนดเอง (Custom multi-agent workflow):**\n",
        "\n",
        "ตัวแทนแต่ละตัวสื่อสารกับเฉพาะชุดย่อยของตัวแทน\n",
        "ส่วนต่างๆ ของโฟลว์มีความแน่นอน และมีเพียงตัวแทนบางตัวเท่านั้นที่สามารถตัดสินใจได้ว่าจะเรียกใช้ตัวแทนอื่นใดต่อไป\n",
        "\n",
        "**ส่วนถัดไปจะเจาะลึกรายละเอียดเพิ่มเติมเกี่ยวกับสถาปัตยกรรมผู้ควบคุม ซึ่งเราคิดว่ามีความสมดุลที่ดีระหว่างความสามารถและความง่ายในการใช้งาน**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLZaqEW5D-ef"
      },
      "source": [
        "## Supervisor Architecture\n",
        "\n",
        "\n",
        "**สถาปัตยกรรมผู้ควบคุม**\n",
        "\n",
        "ในสถาปัตยกรรมนี้ เราเพิ่มตัวแทนแต่ละตัวลงในกราฟเป็นโหนด และเพิ่มโหนดผู้ควบคุม ซึ่งจะตัดสินใจว่าควรเรียกใช้ตัวแทนใดต่อไป เราใช้ขอบที่มีเงื่อนไขเพื่อกำหนดเส้นทางการดำเนินการไปยังโหนดตัวแทนที่เหมาะสมตามการตัดสินใจของผู้ควบคุม อ้างอิงกลับไปที่ บทที่ 5 สำหรับบทนำสู่ LangGraph ซึ่งกล่าวถึงแนวคิดของโหนด ขอบ และอื่นๆ\n",
        "\n",
        "มาดูกันก่อนว่าโหนดผู้ควบคุมมีลักษณะอย่างไร:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XJ0rjrs8Uin"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel\n",
        "\n",
        "class SupervisorDecision(BaseModel):\n",
        "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
        "\n",
        "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "model = model.with_structured_output(SupervisorDecision)\n",
        "\n",
        "agents = [\"researcher\", \"coder\"]\n",
        "\n",
        "system_prompt_part_1 = f\"\"\"\n",
        "You are a supervisor tasked with managing a conversation between the\n",
        "following workers: {agents}. Given the following user request,\n",
        "respond with the worker to act next. Each worker will perform a\n",
        "task and respond with their results and status. When finished,\n",
        "respond with FINISH.\"\"\"\n",
        "\n",
        "system_prompt_part_2 = f\"\"\"\n",
        "Given the conversation above, who should act next?\n",
        "Or should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
        "\n",
        "def supervisor(state):\n",
        "    messages = [\n",
        "        (\"system\", system_prompt_part_1),\n",
        "        *state[\"messages\"],\n",
        "        (\"system\", \tsystem_prompt_part_2)\n",
        "    ]\n",
        "    return model.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from typing import Literal\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# --- Your Provided Code ---\n",
        "class SupervisorDecision(BaseModel):\n",
        "    \"\"\"The decision on the next step.\"\"\"\n",
        "    next: Literal[\"researcher\", \"coder\", \"FINISH\"] = Field(description=\"The next worker to call, or FINISH.\")\n",
        "\n",
        "# --- MOCK MODEL FOR DEMONSTRATION ---\n",
        "# In a real scenario, you'd use your ChatOpenAI setup.\n",
        "# For this example, let's mock the behavior.\n",
        "class MockChatModel:\n",
        "    def invoke(self, messages):\n",
        "        # Simple logic for demo: if 'research' is mentioned, call researcher,\n",
        "        # if 'code' or 'script' is mentioned AND researcher mentioned, call coder,\n",
        "        # otherwise assume finish (or default to researcher if unsure).\n",
        "        last_message_content = messages[-2][1] # Get the last actual message before the system prompt\n",
        "        if \"research\" in last_message_content.lower():\n",
        "             # If the user request contains research, start there\n",
        "             if len(messages) <= 3: # System1, User, System2 -> initial request\n",
        "                print(\"Mock Supervisor: Deciding 'researcher' based on initial request.\")\n",
        "                return SupervisorDecision(next=\"researcher\")\n",
        "             else: # Check if researcher already ran\n",
        "                 researcher_ran = any(\"[Researcher Output]\" in msg[1] for msg in messages if msg[0] == 'assistant')\n",
        "                 if researcher_ran and (\"code\" in last_message_content.lower() or \"script\" in last_message_content.lower()):\n",
        "                     print(\"Mock Supervisor: Deciding 'coder' after researcher.\")\n",
        "                     return SupervisorDecision(next=\"coder\")\n",
        "                 elif researcher_ran: # Researcher ran, but no coding requested or done\n",
        "                     print(\"Mock Supervisor: Deciding 'FINISH' after researcher (no coding needed/done).\")\n",
        "                     return SupervisorDecision(next=\"FINISH\")\n",
        "                 else: # Should have run researcher first\n",
        "                     print(\"Mock Supervisor: Deciding 'researcher' (should have run already?).\")\n",
        "                     return SupervisorDecision(next=\"researcher\")\n",
        "\n",
        "        elif \"code\" in last_message_content.lower() or \"script\" in last_message_content.lower():\n",
        "            coder_ran = any(\"[Coder Output]\" in msg[1] for msg in messages if msg[0] == 'assistant')\n",
        "            if coder_ran:\n",
        "                print(\"Mock Supervisor: Deciding 'FINISH' after coder.\")\n",
        "                return SupervisorDecision(next=\"FINISH\")\n",
        "            else:\n",
        "                 print(\"Mock Supervisor: Deciding 'coder' based on request.\")\n",
        "                 return SupervisorDecision(next=\"coder\") # Assume research not needed or done\n",
        "        else:\n",
        "            print(\"Mock Supervisor: Deciding 'FINISH' (default/unclear request).\")\n",
        "            return SupervisorDecision(next=\"FINISH\")\n",
        "\n",
        "model = MockChatModel() # Use the mock model for this example\n",
        "# model = ChatOpenAI(model=\"gpt-4o\", temperature=0) # Your original model\n",
        "# model = model.with_structured_output(SupervisorDecision) # Your original structuring\n",
        "\n",
        "agents = [\"researcher\", \"coder\"]\n",
        "\n",
        "system_prompt_part_1 = f\"\"\"\n",
        "You are a supervisor tasked with managing a conversation between the\n",
        "following workers: {agents}. Given the following user request,\n",
        "respond with the worker to act next. Each worker will perform a\n",
        "task and respond with their results and status. When finished,\n",
        "respond with FINISH.\"\"\"\n",
        "\n",
        "system_prompt_part_2 = f\"\"\"\n",
        "Given the conversation above, who should act next?\n",
        "Or should we FINISH? Select one of: {', '.join(agents)}, FINISH\"\"\"\n",
        "\n",
        "def supervisor(state):\n",
        "    print(\"\\n--- Supervisor Called ---\")\n",
        "    print(\"Current State Messages:\")\n",
        "    for msg_type, msg_content in state[\"messages\"]:\n",
        "        print(f\"- {msg_type}: {msg_content[:100]}...\") # Print truncated messages\n",
        "    messages = [\n",
        "        (\"system\", system_prompt_part_1),\n",
        "        *state[\"messages\"],\n",
        "        (\"system\",  system_prompt_part_2)\n",
        "    ]\n",
        "    # In a real scenario, ensure your OPENAI_API_KEY is set if using ChatOpenAI\n",
        "    # os.environ[\"OPENAI_API_KEY\"] = \"your-api-key\"\n",
        "    decision = model.invoke(messages)\n",
        "    print(f\"Supervisor Decision: {decision.next}\")\n",
        "    print(\"--- Supervisor Finished ---\")\n",
        "    return {\"next_action\": decision} # Often you return the decision structured for the graph\n",
        "\n",
        "# --- Example Usage ---\n",
        "\n",
        "# 1. Initial call\n",
        "initial_state = {\n",
        "    \"messages\": [(\"user\", \"Please research the company 'FutureTech Inc.' and then write a python script to print its founding year.\")]\n",
        "}\n",
        "supervisor_decision_1 = supervisor(initial_state)\n",
        "# Expected Mock Output (based on simple logic): Supervisor decides 'researcher'\n",
        "\n",
        "# 2. Simulate Researcher's response and call supervisor again\n",
        "state_after_researcher = {\n",
        "    \"messages\": [\n",
        "        (\"user\", \"Please research the company 'FutureTech Inc.' and then write a python script to print its founding year.\"),\n",
        "        (\"assistant\", \"[Researcher Output]: FutureTech Inc. was founded in 2010 according to public records.\") # Researcher adds its result\n",
        "    ]\n",
        "}\n",
        "supervisor_decision_2 = supervisor(state_after_researcher)\n",
        "# Expected Mock Output: Supervisor sees research done, decides 'coder'\n",
        "\n",
        "# 3. Simulate Coder's response and call supervisor again\n",
        "state_after_coder = {\n",
        "     \"messages\": [\n",
        "        (\"user\", \"Please research the company 'FutureTech Inc.' and then write a python script to print its founding year.\"),\n",
        "        (\"assistant\", \"[Researcher Output]: FutureTech Inc. was founded in 2010 according to public records.\"),\n",
        "        (\"assistant\", \"[Coder Output]: ```python\\nprint('FutureTech Inc. Founding Year: 2010')\\n```\") # Coder adds its result\n",
        "    ]\n",
        "}\n",
        "supervisor_decision_3 = supervisor(state_after_coder)\n",
        "# Expected Mock Output: Supervisor sees coding done, decides 'FINISH'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZegu8PfE-vI"
      },
      "source": [
        "**หมายเหตุ :**\n",
        "\n",
        "โค้ดในพรอมต์ต้องการให้ชื่อของตัวแทนย่อยมีความอธิบายและแตกต่างกันอย่างชัดเจน ตัวอย่างเช่น หากเรียกว่า `agent_1` และ `agent_2` อย่างง่ายๆ LLM จะไม่มีข้อมูลในการตัดสินใจว่าตัวใดเหมาะสมสำหรับงานแต่ละอย่าง หากจำเป็น คุณสามารถปรับเปลี่ยนพรอมต์เพื่อเพิ่มคำอธิบายของตัวแทนแต่ละตัว ซึ่งจะช่วยให้ LLM ในการเลือกตัวแทนสำหรับแต่ละคิวรี\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ketqHs5jFFaa"
      },
      "source": [
        "ตอนนี้มาดูวิธีการรวมโหนดผู้ควบคุมนี้เข้ากับกราฟที่ใหญ่กว่าซึ่งรวมถึงตัวแทนย่อยอื่นๆ สองตัว ซึ่งเราจะเรียกว่า `researcher` และ `coder` เป้าหมายโดยรวมของเรากับกราฟนี้คือการจัดการคิวรีที่สามารถตอบกลับได้ทั้งโดย `researcher` เอง หรือ `coder` เอง หรือแม้กระทั่งทั้งคู่ตามลำดับ ตัวอย่างนี้ไม่รวมถึงการใช้งานสำหรับ `researcher` หรือ `coder` แนวคิดหลักคือพวกเขาอาจเป็นกราฟหรือโหนด LangGraph อื่นๆ"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2NdBZAuETd4"
      },
      "outputs": [],
      "source": [
        "from typing import Literal\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, MessagesState, START\n",
        "\n",
        "model = ChatOpenAI()\n",
        "\n",
        "class AgentState(BaseModel):\n",
        "    next: Literal[\"researcher\", \"coder\", \"FINISH\"]\n",
        "\n",
        "def researcher(state: AgentState):\n",
        "    response = model.invoke(...)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "def coder(state: AgentState):\n",
        "    response = model.invoke(...)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "builder = StateGraph(AgentState)\n",
        "builder.add_node(supervisor)\n",
        "builder.add_node(researcher)\n",
        "builder.add_node(coder)\n",
        "\n",
        "builder.add_edge(START, \"supervisor\")\n",
        "# route to one of the agents or exit based on the supervisor's decision\n",
        "builder.add_conditional_edges(\"supervisor\", lambda state: state[\"next\"])\n",
        "builder.add_edge(\"researcher\", \"supervisor\")\n",
        "builder.add_edge(\"coder\", \"supervisor\")\n",
        "\n",
        "supervisor = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Jn3Wn_lVFfeN",
        "outputId": "2cf206e1-1b6b-47bd-b29e-afa72dd27ea1"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "image_bytes = supervisor.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\n",
        "\n",
        "display(Image(data=image_bytes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FIw3gzNMFuUr"
      },
      "source": [
        "**สิ่งที่ควรสังเกต:** ในตัวอย่างนี้ ตัวแทนย่อยทั้งสอง (researcher และ coder) สามารถเห็นงานของกันและกันได้ เนื่องจากความคืบหน้าทั้งหมดถูกบันทึกไว้ในรายการข้อความ สิ่งนี้ไม่ใช่วิธีเดียวในการจัดระเบียบนี้ ตัวแทนย่อยแต่ละตัวอาจมีความซับซ้อนมากขึ้น ตัวอย่างเช่น ตัวแทนย่อยอาจเป็นกราฟของตัวเองที่รักษาสถานะภายในและส่งออกเฉพาะสรุปของงานที่ทำเท่านั้น\n",
        "\n",
        "หลังจากที่ตัวแทนแต่ละตัวดำเนินการ เราจะกำหนดเส้นทางกลับไปยังโหนดผู้ควบคุม ซึ่งจะตัดสินใจว่ามีงานเพิ่มเติมที่ต้องทำหรือไม่ และควรมอบหมายงานนั้นให้กับตัวแทนใด หากเป็นเช่นนั้น การกำหนดเส้นทางนี้ไม่ใช่ข้อกำหนดที่ยากสำหรับสถาปัตยกรรมนี้ เราสามารถให้ตัวแทนย่อยแต่ละตัวตัดสินใจว่าควรส่งออกผลลัพธ์โดยตรงไปยังผู้ใช้หรือไม่ ในการทำเช่นนั้น เราจะแทนที่ขอบคงที่ระหว่าง ตัวอย่างเช่น researcher และ supervisor ด้วยขอบที่มีเงื่อนไข (ซึ่งจะอ่านคีย์สถานะบางอย่างที่อัปเดตโดย researcher)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hierarchical Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import operator\n",
        "from typing import TypedDict, Annotated, Literal, Sequence\n",
        "\n",
        "# Langchain/Langgraph imports (ensure you have langchain and langgraph installed)\n",
        "# pip install langchain langchain_openai langgraph tavily-python\n",
        "from langchain_core.messages import BaseMessage, HumanMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Optional: For real LLM decision making (replace simple logic if needed)\n",
        "# from langchain_core.pydantic_v1 import BaseModel\n",
        "\n",
        "# --- Define the State ---\n",
        "# This dictionary holds the information passed between nodes.\n",
        "class HierarchicalAgentState(TypedDict):\n",
        "    query: str              # The initial user request\n",
        "    supervisor_decision: Literal[\"route_to_a\", \"route_to_b\", \"error\"] # Decision from top supervisor\n",
        "    result_a: str | None    # Result from MidLevelAgentA\n",
        "    result_b: str | None    # Result from MidLevelAgentB\n",
        "    final_result: str       # The final aggregated result\n",
        "\n",
        "# --- Define Nodes (as functions) ---\n",
        "\n",
        "# 1. Top Supervisor Node\n",
        "#    (Using simple logic here; could be an LLM call with structured output)\n",
        "def top_supervisor_node(state: HierarchicalAgentState) -> HierarchicalAgentState:\n",
        "    \"\"\"Decides which mid-level agent to route the query to.\"\"\"\n",
        "    print(\"--- Top Supervisor ---\")\n",
        "    query = state['query']\n",
        "    print(f\"Query: {query}\")\n",
        "    decision: Literal[\"route_to_a\", \"route_to_b\", \"error\"]\n",
        "    if \"alpha\" in query.lower():\n",
        "        print(\"Decision: Route to Mid-Level Agent A\")\n",
        "        decision = \"route_to_a\"\n",
        "    elif \"beta\" in query.lower():\n",
        "        print(\"Decision: Route to Mid-Level Agent B\")\n",
        "        decision = \"route_to_b\"\n",
        "    else:\n",
        "        print(\"Decision: Cannot determine route\")\n",
        "        decision = \"error\" # Or handle error appropriately\n",
        "\n",
        "    return {\"supervisor_decision\": decision, \"result_a\": None, \"result_b\": None} # Reset results\n",
        "\n",
        "# 2. Mid-Level Agent A Node (Simulated work)\n",
        "def mid_level_agent_a_node(state: HierarchicalAgentState) -> HierarchicalAgentState:\n",
        "    \"\"\"Performs Task A.\"\"\"\n",
        "    print(\"--- Mid-Level Agent A ---\")\n",
        "    query = state['query']\n",
        "    # Simulate processing related to \"alpha\"\n",
        "    result = f\"Processed query '{query}' using ALPHA protocol.\"\n",
        "    print(f\"Result: {result}\")\n",
        "    return {\"result_a\": result}\n",
        "\n",
        "# 3. Mid-Level Agent B Node (Simulated work)\n",
        "def mid_level_agent_b_node(state: HierarchicalAgentState) -> HierarchicalAgentState:\n",
        "    \"\"\"Performs Task B.\"\"\"\n",
        "    print(\"--- Mid-Level Agent B ---\")\n",
        "    query = state['query']\n",
        "    # Simulate processing related to \"beta\"\n",
        "    result = f\"Processed query '{query}' using BETA framework.\"\n",
        "    print(f\"Result: {result}\")\n",
        "    return {\"result_b\": result}\n",
        "\n",
        "# 4. Aggregator Node\n",
        "def aggregator_node(state: HierarchicalAgentState) -> HierarchicalAgentState:\n",
        "    \"\"\"Collects results and prepares the final output.\"\"\"\n",
        "    print(\"--- Aggregator ---\")\n",
        "    final_result = \"No result generated.\"\n",
        "    if state.get(\"result_a\"):\n",
        "        final_result = f\"Final Output from A: {state['result_a']}\"\n",
        "    elif state.get(\"result_b\"):\n",
        "        final_result = f\"Final Output from B: {state['result_b']}\"\n",
        "    elif state['supervisor_decision'] == \"error\":\n",
        "         final_result = \"Error: Could not determine appropriate processing path.\"\n",
        "\n",
        "    print(f\"Final Result: {final_result}\")\n",
        "    return {\"final_result\": final_result}\n",
        "\n",
        "# --- Define Conditional Edges ---\n",
        "def route_based_on_decision(state: HierarchicalAgentState) -> Literal[\"mid_level_agent_a\", \"mid_level_agent_b\", \"aggregator\"]:\n",
        "    \"\"\"Determines the next node based on the supervisor's decision.\"\"\"\n",
        "    print(\"--- Routing ---\")\n",
        "    decision = state['supervisor_decision']\n",
        "    if decision == \"route_to_a\":\n",
        "        print(\"Routing to Agent A\")\n",
        "        return \"mid_level_agent_a\"\n",
        "    elif decision == \"route_to_b\":\n",
        "        print(\"Routing to Agent B\")\n",
        "        return \"mid_level_agent_b\"\n",
        "    else: # Handle error or unexpected cases\n",
        "        print(\"Routing directly to Aggregator (Error case)\")\n",
        "        return \"aggregator\" # Go directly to aggregator to report the error\n",
        "\n",
        "# --- Build the Graph ---\n",
        "workflow = StateGraph(HierarchicalAgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"top_supervisor\", top_supervisor_node)\n",
        "workflow.add_node(\"mid_level_agent_a\", mid_level_agent_a_node)\n",
        "workflow.add_node(\"mid_level_agent_b\", mid_level_agent_b_node)\n",
        "workflow.add_node(\"aggregator\", aggregator_node)\n",
        "\n",
        "# Define edges\n",
        "workflow.set_entry_point(\"top_supervisor\")\n",
        "\n",
        "# Conditional edge from supervisor to mid-level agents or aggregator\n",
        "workflow.add_conditional_edges(\n",
        "    \"top_supervisor\",\n",
        "    route_based_on_decision,\n",
        "    {\n",
        "        \"mid_level_agent_a\": \"mid_level_agent_a\",\n",
        "        \"mid_level_agent_b\": \"mid_level_agent_b\",\n",
        "        \"aggregator\": \"aggregator\", # Route directly if decision was error\n",
        "    }\n",
        ")\n",
        "\n",
        "# Edges from mid-level agents to the aggregator\n",
        "workflow.add_edge(\"mid_level_agent_a\", \"aggregator\")\n",
        "workflow.add_edge(\"mid_level_agent_b\", \"aggregator\")\n",
        "\n",
        "# The aggregator node leads to the end\n",
        "workflow.add_edge(\"aggregator\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "# --- Run the Graph ---\n",
        "\n",
        "print(\"\\n--- Running Graph with 'alpha' query ---\")\n",
        "inputs_a = {\"query\": \"Please process the request for alpha team.\"}\n",
        "result_a_run = app.invoke(inputs_a)\n",
        "print(\"\\nFinal State (A):\", result_a_run)\n",
        "\n",
        "\n",
        "print(\"\\n\\n--- Running Graph with 'beta' query ---\")\n",
        "inputs_b = {\"query\": \"Need to execute the beta workflow.\"}\n",
        "result_b_run = app.invoke(inputs_b)\n",
        "print(\"\\nFinal State (B):\", result_b_run)\n",
        "\n",
        "\n",
        "print(\"\\n\\n--- Running Graph with 'unknown' query ---\")\n",
        "inputs_c = {\"query\": \"What is the weather today?\"}\n",
        "result_c_run = app.invoke(inputs_c)\n",
        "print(\"\\nFinal State (C):\", result_c_run)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from langchain_core.runnables.graph import CurveStyle, MermaidDrawMethod, NodeStyles\n",
        "\n",
        "image_bytes = app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\n",
        "\n",
        "display(Image(data=image_bytes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMotv8DwGJ6b"
      },
      "source": [
        "# Summary\n",
        "**สรุป**\n",
        "\n",
        "บทนี้กล่าวถึงส่วนขยายที่สำคัญสองส่วนของสถาปัตยกรรมตัวแทน: การสะท้อนกลับ (Reflection) และสถาปัตยกรรมหลายตัวแทน (Multi-agent Architectures) บทนี้ยังได้กล่าวถึงวิธีการทำงานกับ subgraphs ใน LangGraph ซึ่งเป็นส่วนประกอบหลักสำหรับระบบหลายตัวแทน\n",
        "\n",
        "ส่วนขยายเหล่านี้เพิ่มพลังให้กับสถาปัตยกรรมตัวแทน LLM มากขึ้น แต่ไม่ควรเป็นสิ่งแรกที่คุณคว้ามาเมื่อสร้างตัวแทนใหม่ สถานที่ที่ดีที่สุดในการเริ่มต้นมักจะเป็นสถาปัตยกรรมตรงไปตรงมาที่เราได้กล่าวถึงใน บทที่ 6\n",
        "\n",
        "บทที่ 8 กลับมาที่การแลกเปลี่ยนระหว่างความน่าเชื่อถือ (Reliability) และความเป็นอิสระ (Agency) ซึ่งเป็นการตัดสินใจออกแบบที่สำคัญเมื่อสร้างแอปพลิเคชัน LLM ในปัจจุบัน สิ่งนี้มีความสำคัญอย่างยิ่งเมื่อใช้สถาปัตยกรรมตัวแทนหรือหลายตัวแทน เนื่องจากพลังของสถาปัตยกรรมเหล่านี้มาพร้อมกับค่าใช้จ่ายของความน่าเชื่อถือหากปล่อยทิ้งไว้โดยไม่ได้รับการตรวจสอบ หลังจากเจาะลึกลงไปว่าเหตุใดการแลกเปลี่ยนนี้จึงมีอยู่\n",
        "\n",
        "**บทที่ 8 จะกล่าวถึงเทคนิคที่สำคัญที่สุดที่มีให้คุณเพื่อนำทางการตัดสินใจนั้น และในที่สุดก็ปรับปรุงแอปพลิเคชันและตัวแทน LLM ของคุณ**\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
